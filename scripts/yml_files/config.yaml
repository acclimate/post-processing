logging: 
  distributed: info
  distributed.client: warning
  bokeh: critical
  # http://stackoverflow.com/questions/21234772/python-tornado-disable-logging-to-stderr
  tornado: critical
  tornado.application: error

compression: null

# Scheduler options
bandwidth: 1000000000    # 1000 MB/s estimated worker-worker bandwidth
allowed-failures: 3     # number of retries before a task is considered bad
pdb-on-err: False       # enter debug mode on scheduling error
transition-log-length: 100000 
work-stealing: True     # workers should steal tasks from each other


distributed:
  scheduler:
    bandwidth: 1000000000     # GB MB/s estimated worker-worker bandwidth
    allowed-failures: 3     # number of retries before a task is considered bad
    pdb-on-err: False       # enter debug mode on scheduling error
    transition-log-length: 100000 
    work-stealing: True     # workers should steal tasks from each other

  worker:
    memory:
      target: False  # Avoid spilling to disk
      spill: False  # Avoid spilling to disk
      pause: 0.80  # fraction at which we pause worker threads
      terminate: 0.95  # fraction at which we terminate the worker
  comm:
    compression: null
    
    
# Worker options
multiprocessing-method: forkserver

# Communication options
connect-timeout: 5      # seconds delay before connecting fails
tcp-timeout: 30         # seconds delay before calling an unresponsive connection dead
default-scheme: ib0
require-encryption: False   # whether to require encryption on non-local comms
socket-backlog: 2048
#tls:
    #ca-file: xxx.pem
    #scheduler:
        #key: xxx.pem
        #cert: xxx.pem
    #worker:
        #key: xxx.pem
        #cert: xxx.pem
    #client:
        #key: xxx.pem
        #cert: xxx.pem
    #ciphers:
        #ECDHE-ECDSA-AES128-GCM-SHA256

# Bokeh web dashboard
bokeh-export-tool: False

tick-time: 200             # milliseconds between event loop health checks
tick-maximum-delay: 1000  # milliseconds allowed before triggering a warning

profile-interval: 1000  # milliseconds in between statistical profiling queries
profile-cycle-interval: 100000  # milliseconds between starting new profile


jobqueue:
  slurm:
    name: dask-worker
    # Dask worker options
    death-timeout: 60           # Number of seconds to wait if a worker can not find a scheduler
    cores: 1                    # Total number of cores per job
    processes: 1
    memory: '4 GB'             # Total amount of memory per job
    interface: ib0
    project: "acclimat"
    


